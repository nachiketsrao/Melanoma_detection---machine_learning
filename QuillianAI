{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QuillianAI","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMO3yjSWoSAX26J+4kX/Xjb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-chM4GEluyJ","executionInfo":{"status":"ok","timestamp":1608995527702,"user_tz":-330,"elapsed":5194,"user":{"displayName":"Nachiket Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOWPlXuMt1qYnFubTW0QLwWol8Q4RaBXBSpmFxQA=s64","userId":"17336843626719524237"}},"outputId":"f8b269c0-f079-4b93-ef40-9258d4c67af8"},"source":["\r\n","%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import pandas as pd\r\n","import os\r\n","from glob import glob\r\n","import seaborn as sns\r\n","from PIL import Image\r\n","np.random.seed(11) \r\n","from sklearn.preprocessing import StandardScaler \r\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\r\n","from sklearn.metrics import accuracy_score\r\n","import itertools\r\n","\r\n","import keras\r\n","from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\r\n","from keras.models import Sequential, Model\r\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\r\n","from keras import backend as K\r\n","from keras.layers.normalization import BatchNormalization\r\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\r\n","from keras.optimizers import Adam, RMSprop\r\n","from keras.preprocessing.image import ImageDataGenerator # for augmentation\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.wrappers.scikit_learn import KerasClassifier\r\n","from keras.applications.resnet50 import ResNet50\r\n","from keras.applications.xception import Xception\r\n","from keras.applications.xception import preprocess_input # for augmentation\r\n","import keras.applications\r\n","help(keras.applications)\r\n","print(keras.__version__)\r\n","from keras import backend as K "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Help on package keras.applications in keras:\n","\n","NAME\n","    keras.applications\n","\n","PACKAGE CONTENTS\n","    densenet\n","    imagenet_utils\n","    inception_resnet_v2\n","    inception_v3\n","    mobilenet\n","    mobilenet_v2\n","    nasnet\n","    resnet\n","    resnet50\n","    resnet_v2\n","    vgg16\n","    vgg19\n","    xception\n","\n","FILE\n","    /usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\n","\n","\n","2.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eggRZXO4mwKm"},"source":["from scipy import ndimage\r\n","\r\n","from scipy import misc\r\n","import imageio\r\n","f = misc.face()\r\n","imageio.imsave('face.png', f) # uses the Image module (PIL)\r\n","face = imageio.imread('face.png')\r\n","type(face)      \r\n","\r\n","print(face.shape,'   ', face.dtype)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.imshow(f)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6PF_tUYhvKlo"},"source":["from google.colab import drive\r\n","from pathlib import Path\r\n","\r\n","drive.mount('/content/drive')\r\n","# ref : https://medium.com/datadriveninvestor/speed-up-your-image-training-on-google-colab-dc95ea1491cf\r\n","\r\n","zip_path = '/content/drive/My Drive/Melanoma_project/image_folder.zip'\r\n","!cp \"{zip_path}\" .\r\n","!unzip -q image_folder.zip\r\n","!rm image_folder.zip  # to copy the zip from drive to colab and then get the data - makes the loading process much faster"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_jf5ajfxzH-"},"source":["# Load in training pictures \n","import os\n","ims_benign = [read(os.path.join('/content/train/benign', filename)) for filename in os.listdir('/content/train/benign')]\n","X_benign = np.array(ims_benign, dtype='uint8')\n","ims_malignant = [read(os.path.join('/content/train/malignant', filename)) for filename in os.listdir('/content/train/malignant')]\n","X_malignant = np.array(ims_malignant, dtype='uint8')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJgW24wfvrSu"},"source":["# Load in testing pictures\r\n","\r\n","ims_benign = [read(os.path.join('/content/test/benign', filename)) for filename in os.listdir('/content/test/benign')]\r\n","X_benign_test = np.array(ims_benign, dtype='uint8')\r\n","ims_malignant = [read(os.path.join('/content/test/malignant', filename)) for filename in os.listdir('/content/test/malignant')]\r\n","X_malignant_test = np.array(ims_malignant, dtype='uint8')\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sq_TiCnWvwuE"},"source":["# Create labels\r\n","\r\n","y_benign = np.zeros(X_benign.shape[0])\r\n","y_malignant = np.ones(X_malignant.shape[0])\r\n","\r\n","y_benign_test = np.zeros(X_benign_test.shape[0])\r\n","y_malignant_test = np.ones(X_malignant_test.shape[0])\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4VLK8asvzJT"},"source":["# Merge data \r\n","X_train = np.concatenate((X_benign, X_malignant), axis = 0)\r\n","y_train = np.concatenate((y_benign, y_malignant), axis = 0)\r\n","\r\n","X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\r\n","y_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPiU2c7Qv3v1"},"source":["# Shuffle data\r\n","s = np.arange(X_train.shape[0])\r\n","np.random.shuffle(s)\r\n","X_train = X_train[s]\r\n","print(len(X_train))\r\n","y_train = y_train[s]\r\n","\r\n","s = np.arange(X_test.shape[0])\r\n","np.random.shuffle(s)\r\n","X_test = X_test[s]\r\n","print(X_test)\r\n","print(len(X_test))\r\n","y_test = y_test[s]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XlicBo9ojwG","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"error","timestamp":1608997556911,"user_tz":-330,"elapsed":105624,"user":{"displayName":"Nachiket Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOWPlXuMt1qYnFubTW0QLwWol8Q4RaBXBSpmFxQA=s64","userId":"17336843626719524237"}},"outputId":"fbcb1dd6-ec9b-4f20-b672-2eb3ebfe81e2"},"source":["from keras.preprocessing import image \r\n","import numpy as np \r\n","\r\n","from google.colab import drive\r\n","from pathlib import Path\r\n","\r\n","drive.mount('/content/drive')\r\n","\r\n","# Pre-processing the image \r\n","img = image.load_img('/content/test/malignant/1007.jpg', target_size = (224,224)) \r\n","img_tensor = image.img_to_array(img) \r\n","img_tensor = np.expand_dims(img_tensor, axis = 0) \r\n","img_tensor = img_tensor / 255.\r\n","\r\n","print(img_tensor)\r\n","\r\n","# Print image tensor shape \r\n","print(img_tensor.shape) \r\n","\r\n","# Print image \r\n","import matplotlib.pyplot as plt \r\n","plt.imshow(img_tensor[0]) \r\n","plt.show() "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e363d02fe5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Pre-processing the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test/malignant/1007.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m    299\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 300\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/test/malignant/1007.jpg'"]}]},{"cell_type":"code","metadata":{"id":"RoMJiSKPtKST"},"source":[""],"execution_count":null,"outputs":[]}]}